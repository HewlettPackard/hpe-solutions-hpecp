###
## Copyright (2020) Hewlett Packard Enterprise Development LP
##
## Licensed under the Apache License, Version 2.0 (the "License");
## You may not use this file except in compliance with the License.
## You may obtain a copy of the License at
##
## http://www.apache.org/licenses/LICENSE-2.0
##
## Unless required by applicable law or agreed to in writing, software
## distributed under the License is distributed on an "AS IS" BASIS,
## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
## See the License for the specific language governing permissions and
## limitations under the License.
####
---
bundle_name: hpe-cp-bundle
tools_dir: "{{ lookup('env','HOME') }}/tools"                                               # place to store the kits like kubectl
k8skubeconfig_dir: "{{ lookup('env','HOME') }}/k8skubeconfig"
kubectl_cli_version: v1.17.5

credentials:
  ssh:
    username: <username>   # Update the variable with controller node username
    password: <password>   # Update the variable with controller node password

os: 
  value: False # For CentOS or RHEL set value as "True". For Sles set value as  "False".

common:
  platform: onprem  # No need to change
  #proxy:
  #  http: http://myproxy.com:8080
  #  https: http://myproxy.com:8080
  #  no_proxy: "localhost, 127.0.0.1, 10.1.10.0/24,172.20.0.0/16,10.244.0.0/16,10.96.0.0/16"
  name: OnPremSetup   # No need to change
  #certs:
  #  ssl_cert_file: /tmp/server.crt
  #  ssl_cert_key_file: /tmp/server.key

init:
  host_ip: 20.x.x.x # provide controller node ip

controller:
  url_bin_path: https://my.s3.amazonaws.com/hpe-cp-bundle.bin # Make sure to change this url to correct bundle file or point to the local downloaded bin file path with executable permission ( ex:local:///root/hpe-cp-bundle.bin.)
  host_ip: 20.x.x.x # Provide controller node ip
  bd_domain: bddomain # No need to change
  bd_prefix: bluedata # No need to change
  hdfs_disks: /dev/sdc # Need to be empty when user want to deploy hpecp without tenant 
  no_tenant_isolation: false # In case if there is no requirement of using hdfs_disks, set this value to true.
  no_tenant_storage: false # In case if there is no requirement of using hdfs_disks, set this value to true
  node_disks: /dev/sdb # Provide which disk need to be used as node_disk for ephmeral storage
  int_start_ip: 172.20.0.2 # No need to change
  int_end_ip: 172.20.255.254  # No need to change
  int_gw_ip: 172.20.0.1  # No need to change
  int_nw_mask: 16   # No need to change
  #controller_public_if: ens192 # If multiple interfaces with IP address assignments found. Use --controller-public-if to specify a public interface.

# epic workers
epicworkers:   # Provide epic workers information. Epic worker details are mandatory in case if user want to enable controller ha
  host_pools:
    - name: worker1    # Name of the epic worker
      worker: 20.x.x.x
    - name: worker2      
      worker: 20.x.x.x
  hdfs_disks: /dev/sdc # Need to be empty when user want to deploy hpecp without tenant 
  node_disks: /dev/sdb # Provide which disk need to be used as node_disk for ephemeral  storage

# for k8s cluster
k8shosts: # Provide k8 nodes information
  host_pools:
    - name: worker1   # Name of the node
      host: 20.x.x.x
    - name: worker2
      host: 20.x.x.x
    - name: worker3
      host: 20.x.x.x
  ephemeral_disks: /dev/sdb  # Provide which disk need to be used as ephermal_disk
  persistent_disks: /dev/sdc  # Provide which disk need to be used as persistent disk

  # Set persistent_disks value empty in case if user want to deploy hpecp whit hout tenant

gateway: # Provide gateway nodes information
  host_pools:
    - name: gateway1 
      gateway: 20.x.x.x
      gateway_set_hostname: gatewayhpcpsles.jm.twentynet.local  # Host name of the gateway node
    - name: gateway2
      gateway: 20.x.x.x
      gateway_set_hostname: gatewayhpcpsles.jm.twentynet.local
  
controllerha:  # Provide cluster ip and FQDN name details for enabling controller ha
  clusterip: 20.x.x.x
  cluster_dns_name: vishha.jm.twentynet.local # Provide FQDN name. for example: cluster.local

k8scluster:  # Provide details of k8 cluster
  name: "cluster01"  # Name of the cluster
  description: "my first cluster"
  # TODO: get the host url through API
  host_pools:  # Provide role, ip, k8 version details
    - name: master-pool
      role: master    # Provide node role
      host: "20.x.x.x
    - name: worker-pool
      role: worker
      host: "20.x.x.x
    - name: worker-pool
      role: worker
      host: "20.x.x.x
  k8sversion: "1.17.4"   # Provide k8 version 
  pod_network_range: "10.244.0.0/16"
  service_network_range: "10.96.0.0/16"
  pod_dns_domain: "cluster.local"
  persistent_storage: 
    nimble_csi: false

k8stenant:  # Provide tenant details.
  name: "test01"
  description: "my first tenant01"
  tenant_type_info:
    map_services_to_gateway: true
    specified_namespace_name: test01
    is_namespace_owner: true
    adopt_existing_namespace: false
  tenant_type: k8s
  features:
    ml_project: false
  is_namespace_owner: true
  quota:     # Provide quota details
    memory: 20480 # 20x1024
    persistent: 35840 # 35x1024
    gpus: ""
    cores: 12
    disk: 25600 # 25x1024
    tenant_storage: 30
  k8s_cluster: "cluster01"    # Provide cluster name
  specified_namespace_name: "test01" 
  map_services_to_gateway: true
  adopt_existing_namespace: false
  krb_enc_types: []

